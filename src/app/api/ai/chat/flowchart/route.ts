import { canUserUseAI, recordAIUsage } from '@/lib/ai-usage';
import { auth } from '@/lib/auth';
import { canGuestUseAI, recordGuestAIUsage } from '@/lib/guest-usage';
import { headers } from 'next/headers';
import OpenAI from 'openai';

// OpenRouter å®¢æˆ·ç«¯é…ç½®
function createOpenAIClient() {
  return new OpenAI({
    baseURL: 'https://openrouter.ai/api/v1',
    apiKey: process.env.OPENROUTER_API_KEY,
    defaultHeaders: {
      'HTTP-Referer':
        process.env.NEXT_PUBLIC_BASE_URL || 'http://localhost:3000',
      'X-Title': 'FlowChart AI',
    },
  });
}

// æµç¨‹å›¾ç”Ÿæˆå·¥å…·å®šä¹‰
const flowchartTool = {
  type: 'function' as const,
  function: {
    name: 'generate_flowchart',
    description: 'Generate or update a flowchart using Mermaid syntax',
    parameters: {
      type: 'object',
      properties: {
        mermaid_code: {
          type: 'string',
          description: 'Valid Mermaid flowchart code',
        },
        mode: {
          type: 'string',
          enum: ['replace', 'extend'],
          description:
            'Whether to replace existing flowchart completely or extend/modify it based on existing content',
        },
        description: {
          type: 'string',
          description: 'Brief description of the flowchart',
        },
      },
      required: ['mermaid_code', 'mode', 'description'],
    },
  },
};

// ç³»ç»Ÿæç¤ºè¯
function generateSystemPrompt(canvasSummary?: string, lastMermaid?: string) {
  const contextSection = [
    canvasSummary
      ? `CURRENT CANVAS SNAPSHOT (JSON):\n${canvasSummary}`
      : 'CURRENT CANVAS SNAPSHOT: none provided',
    lastMermaid
      ? `LATEST AI MERMAID (may be outdated if user edited manually):\n\n\`\`\`mermaid\n${lastMermaid}\n\`\`\``
      : 'LATEST AI MERMAID: none recorded',
  ].join('\n\n');

  return `ä½ æ˜¯ FlowChart AIï¼Œä¸€åä¸“æ³¨äºå¸®åŠ©ç”¨æˆ·é«˜æ•ˆæ„å»ºå†…å®¹è¯¦å®æµç¨‹å›¾çš„æ™ºèƒ½åŠ©æ‰‹ã€‚ä½¿ç”¨ä¸ç”¨æˆ·ç›¸åŒçš„è¯­è¨€è¿›è¡Œå›å¤ï¼ˆé»˜è®¤ä¸­æ–‡ï¼‰ã€‚

å½“å‰ç”»å¸ƒä¸Šä¸‹æ–‡ï¼š
${contextSection}

å¯ç”¨å·¥å…·ï¼š
- **generate_flowchart**ï¼ˆå”¯ä¸€å‡½æ•°å·¥å…·ï¼‰ã€‚å½“éœ€è¦ç”Ÿæˆæˆ–æ›´æ–°æµç¨‹å›¾æ—¶è°ƒç”¨ï¼Œè¿”å› Mermaid æ–‡æœ¬ã€‚è°ƒç”¨åä¸è¦åœ¨å›å¤ä¸­ç›´æ¥å±•ç¤º Mermaid ä»£ç ï¼Œåªéœ€ç”¨è‡ªç„¶è¯­è¨€æ¦‚è¿°ç»“æœã€‚

æ ¸å¿ƒèŒè´£ï¼š
1. å…³é”®ä»»åŠ¡ï¼šç†è§£ç”¨æˆ·åœºæ™¯ï¼Œè¾“å‡ºå¯ç”¨äºç”Ÿæˆæµç¨‹å›¾çš„è¯¦å°½èŠ‚ç‚¹ä¸è¿æ¥æè¿°ï¼Œæå‡æµç¨‹è®¾è®¡æ•ˆç‡ã€‚
2. é—®ç­”ç­–ç•¥ï¼š
   - ç”¨æˆ·ç›´æ¥è¯·æ±‚æµç¨‹å›¾ï¼šè‹¥ä¿¡æ¯å……åˆ†ï¼Œç›´æ¥è§„åˆ’ï¼›è‹¥å…³é”®æ„å›¾ä¸æ¸…æ™°ï¼Œä»…æå‡º 1â€“2 ä¸ªé«˜ä»·å€¼æ¾„æ¸…é—®é¢˜åå†è¡ŒåŠ¨ã€‚
   - ç”¨æˆ·æå‡ºä¸€èˆ¬æ€§é—®é¢˜ï¼ˆå¦‚â€œå¦‚ä½•ä¸Šä¼ åšå®¢æ–‡ç« â€ï¼‰ï¼šå…ˆå®Œæ•´å›ç­”ï¼Œå†è¯¢é—®æ˜¯å¦éœ€è¦æŠŠä¸Šè¿°å†…å®¹è½¬åŒ–ä¸ºæµç¨‹å›¾ã€‚
   - ç”¨æˆ·å’¨è¯¢ Agent è‡ªèº«ã€ç”»å¸ƒçŠ¶æ€æˆ–ç³»ç»Ÿè®¾å®šï¼šç›´æ¥è§£ç­”ï¼Œæ— éœ€è°ƒç”¨å·¥å…·ã€‚
3. éœ€æ±‚ç¡®è®¤ï¼šåœ¨è°ƒç”¨å·¥å…·å‰ç¡®ä¿äº†è§£æµç¨‹ç›®æ ‡ã€å…³é”®æ­¥éª¤ã€è§’è‰²/å·¥å…·ã€åˆ†æ”¯æ¡ä»¶ç­‰ï¼›è‹¥å…³é”®ç‚¹ç¼ºå¤±ï¼Œå¯è¿›è¡Œä¸€æ¬¡é›†ä¸­æ¾„æ¸…ï¼Œé¿å…å¤šè½®è¿½é—®ã€‚å°†æ•´ä½“æµç¨‹å…ˆæ‹†åˆ†ä¸ºè‹¥å¹²é˜¶æ®µ/å­æ¨¡å—ï¼Œå†é€ä¸ªç»†åŒ–ã€‚
4. æµç¨‹å›¾ç”Ÿæˆè§„èŒƒï¼š
   - ç”Ÿæˆæ–¹æ¡ˆå¿…é¡»å…·å¤‡é«˜å¤æ‚åº¦ï¼šé’ˆå¯¹æ¯ä¸ªé˜¶æ®µè‡³å°‘ç»†åˆ† 3â€“5 ä¸ªå¯æ‰§è¡Œæ­¥éª¤æˆ–å†³ç­–èŠ‚ç‚¹ï¼Œå¹¶è¡¥å……è¾“å…¥/è¾“å‡ºã€è´£ä»»è§’è‰²ã€å·¥å…·/ç³»ç»Ÿã€äº§å‡ºç‰©ä»¥åŠå…³é”®æŒ‡æ ‡ã€‚è‹¥å­˜åœ¨å¤±è´¥è·¯å¾„ã€å®¡æ‰¹ã€å›æ»šã€ç›‘æ§æˆ–æŒç»­æ”¹è¿›ç¯èŠ‚ï¼Œåº”ä¸»åŠ¨æ·»åŠ ï¼Œé™¤éç”¨æˆ·è¦æ±‚â€œç®€å•/æ¦‚è§ˆâ€ã€‚
   - åœ¨æ„æ€æµç¨‹å›¾æ—¶ï¼Œå…ˆè¾“å‡ºåˆ†å±‚ç»“æ„ï¼šå…ˆåˆ—å‡ºä¸€çº§é˜¶æ®µï¼ˆæ¨¡å—/å°èŠ‚ï¼‰ï¼Œå†åœ¨æ¯ä¸ªé˜¶æ®µå†…ç»§ç»­æ‹†åˆ†åˆ°å¯æ‰§è¡Œæ­¥éª¤æˆ–å†³ç­–ç‚¹ï¼›ç¡®ä¿æœ€ç»ˆæµç¨‹å›¾æ˜¾å¼å‘ˆç°è¿™ç§å±‚æ¬¡å…³ç³»ï¼Œå¹¶è¦†ç›–ä¸»æµç¨‹ã€å¤‡ç”¨æµç¨‹ã€è´¨é‡æ£€æŸ¥åŠåé¦ˆé—­ç¯ã€‚
   - é»˜è®¤ä½¿ç”¨æ¨ªå‘è¡¨ç°å½¢å¼â€”â€”ä¼˜å…ˆé€‰æ‹© Mermaid \`sequenceDiagram\`ï¼Œå……åˆ†åˆ©ç”¨ participantã€noteã€alt/opt/loopã€par ç­‰ç»“æ„è¡¨è¾¾å¹¶å‘ã€æ¡ä»¶ã€å¼‚å¸¸ä¸åé¦ˆï¼›ä»…åœ¨ç”¨æˆ·æ˜ç¡®è¦æ±‚æˆ–äº¤äº’é€»è¾‘ä¸é€‚åˆ \`sequenceDiagram\` æ—¶ï¼Œæ”¹ç”¨ \`flowchart\`/\`graph\` ç­‰å…¶ä»–ç±»å‹ï¼Œå¹¶åœ¨è¯´æ˜ä¸­è§£é‡ŠåŸå› ã€‚
   - å·¥å…·è°ƒç”¨åï¼Œç”¨è‡ªç„¶è¯­è¨€æ€»ç»“æ–°å¢èŠ‚ç‚¹ã€åˆ†æ”¯åŠé‡ç‚¹æç¤ºï¼Œé¼“åŠ±ç”¨æˆ·ç»§ç»­è¿­ä»£ã€‚
5. å®‰å…¨åˆè§„ï¼šæ‹’ç»æˆ–è°¨æ…å¤„ç†æ•æ„Ÿã€è¿æ³•ã€è¿åæ”¿ç­–çš„è¯·æ±‚ã€‚

æ²Ÿé€šæ ¼å¼å»ºè®®ï¼š
- é‡‡ç”¨â€œæ¦‚è¿° â†’ å…³é”®ä¿¡æ¯/ç–‘é—® â†’ ä¸‹ä¸€æ­¥æˆ–æ€»ç»“â€çš„ç»“æ„ï¼Œè¯­è¨€ç¤¼è²Œã€ä¸“ä¸šã€æ¸…æ™°ã€‚
- ä»…åœ¨ä¿¡æ¯å……åˆ†æ—¶è°ƒç”¨ generate_flowchartï¼›è‹¥è°ƒç”¨å¤±è´¥æˆ–æ— æ³•ç”Ÿæˆï¼Œåº”è¯´æ˜åŸå› å¹¶ç»™å‡ºå¯è¡Œçš„åç»­å»ºè®®ã€‚
- ä¿æŒäº¤æµèšç„¦äºå¸®åŠ©ç”¨æˆ·ä¼˜åŒ–æµç¨‹è®¾è®¡ä½“éªŒã€‚

MODE è¡Œä¸ºï¼š
- **replace**ï¼šç”¨æˆ·æƒ³é‡å»ºæµç¨‹ï¼Œæˆ–ç”»å¸ƒæ—  AI å…ƒç´  â†’ ç”¨æ–°æµç¨‹è¦†ç›–æ—§å†…å®¹ã€‚
- **extend**ï¼šç”»å¸ƒå·²æœ‰ AI å…ƒç´ ä¸”ç”¨æˆ·æƒ³å¢é‡æ‰©å±• â†’ ä¿ç•™ç°æœ‰èŠ‚ç‚¹ï¼Œåªæ–°å¢æˆ–ä¿®æ”¹ç›¸å…³éƒ¨åˆ†ã€‚
- è‹¥ UI æˆ–ç”¨æˆ·æŒ‡å®šäº†æ¨¡å¼ï¼Œä¸¥æ ¼éµå¾ªã€‚

å§‹ç»ˆä¿æŒç¤¼è²Œã€æ¸…æ™°ã€ä¸“ä¸šï¼Œèšç„¦äºæå‡ç”¨æˆ·çš„æµç¨‹è®¾è®¡æ•ˆç‡ã€‚`;
}

export async function POST(req: Request) {
  let userId: string | null = null;
  let isGuestUser = false;

  try {
    // 1. èº«ä»½éªŒè¯ - æ”¯æŒguestç”¨æˆ·
    const session = await auth.api.getSession({
      headers: await headers(),
    });

    if (session?.user?.id) {
      userId = session.user.id;
    } else {
      // Guest user - check if they can use AI
      isGuestUser = true;
      const guestCheck = await canGuestUseAI(req);

      if (!guestCheck.canUse) {
        return new Response(
          JSON.stringify({
            error: 'Guest usage limit exceeded',
            message:
              guestCheck.reason ||
              'Guest users can only use AI once per month. Please sign up for more requests.',
            isGuest: true,
            lastUsed: guestCheck.lastUsed,
          }),
          {
            status: 429,
            headers: { 'Content-Type': 'application/json' },
          }
        );
      }
    }

    // 2. æ£€æŸ¥AIä½¿ç”¨é‡é™åˆ¶ (ä»…å¯¹ç™»å½•ç”¨æˆ·)
    if (!isGuestUser) {
      const usageCheck = await canUserUseAI(userId!);
      if (!usageCheck.canUse) {
        return new Response(
          JSON.stringify({
            error: 'Usage limit exceeded',
            message: `You have reached your AI usage limit. ${usageCheck.remainingUsage} of ${usageCheck.limit} requests remaining.`,
            usageInfo: usageCheck,
          }),
          {
            status: 429,
            headers: { 'Content-Type': 'application/json' },
          }
        );
      }
    }

    // 3. éªŒè¯è¯·æ±‚æ•°æ®
    const body = await req.json();
    const { messages, model = 'google/gemini-2.5-flash', aiContext } = body;

    if (!messages || !Array.isArray(messages)) {
      return new Response(
        JSON.stringify({ error: 'Invalid messages format' }),
        {
          status: 400,
          headers: { 'Content-Type': 'application/json' },
        }
      );
    }

    // 4. å‡†å¤‡æ¶ˆæ¯
    const snapshotSummary = aiContext?.canvasSnapshot
      ? JSON.stringify(
          {
            nodes: aiContext.canvasSnapshot.nodes,
            edges: aiContext.canvasSnapshot.edges,
            metadata: aiContext.canvasSnapshot.metadata,
            description: aiContext.canvasSnapshot.description,
          },
          null,
          2
        )
      : undefined;

    const systemMessage = {
      role: 'system' as const,
      content: generateSystemPrompt(
        snapshotSummary,
        aiContext?.lastMermaid?.code || undefined
      ),
    };

    const contextMessages: Array<{
      role: 'system' | 'assistant';
      content: string;
    }> = [];

    if (aiContext?.requestedMode) {
      contextMessages.push({
        role: 'system',
        content: `Requested mode from UI: ${aiContext.requestedMode}`,
      });
    }

    const fullMessages = [systemMessage, ...contextMessages, ...messages];

    // 5. è°ƒç”¨ OpenRouter API
    const openai = createOpenAIClient();

    console.log(
      `ğŸš€ Starting AI conversation with ${fullMessages.length} messages (${isGuestUser ? 'Guest' : 'User'})`
    );

    const completion = await openai.chat.completions.create({
      model: model,
      messages: fullMessages,
      tools: [flowchartTool],
      tool_choice: 'auto',
      temperature: 0.7,
      stream: true,
    });

    console.log('âœ… OpenRouter API call successful, starting stream');

    // 6. è®°å½•AIä½¿ç”¨æƒ…å†µ
    if (isGuestUser) {
      await recordGuestAIUsage(req, 'flowchart_generation', true);
    } else {
      await recordAIUsage(userId!, 'flowchart_generation', {
        tokensUsed: 0,
        model: model,
        success: true,
        metadata: {
          messageCount: messages.length,
        },
      });
    }

    // 7. åˆ›å»ºæµå¼å“åº”
    const encoder = new TextEncoder();
    const stream = new ReadableStream({
      async start(controller) {
        try {
          const toolCalls: any[] = [];
          let accumulatedContent = '';

          for await (const chunk of completion) {
            const delta = chunk.choices[0]?.delta;

            if (delta?.content) {
              accumulatedContent += delta.content;
              const data = JSON.stringify({
                type: 'text',
                content: delta.content,
              });
              controller.enqueue(encoder.encode(`data: ${data}\n\n`));
            }

            if (delta?.tool_calls) {
              for (const toolCall of delta.tool_calls) {
                if (!toolCalls[toolCall.index]) {
                  toolCalls[toolCall.index] = {
                    id: toolCall.id,
                    type: toolCall.type,
                    function: { name: '', arguments: '' },
                  };
                }

                if (toolCall.function?.name) {
                  toolCalls[toolCall.index].function.name =
                    toolCall.function.name;
                }

                if (toolCall.function?.arguments) {
                  toolCalls[toolCall.index].function.arguments +=
                    toolCall.function.arguments;
                }
              }
            }

            if (chunk.choices[0]?.finish_reason === 'tool_calls') {
              // å¤„ç†å·¥å…·è°ƒç”¨
              for (const toolCall of toolCalls) {
                if (toolCall.function.name === 'generate_flowchart') {
                  try {
                    const args = JSON.parse(toolCall.function.arguments);
                    const data = JSON.stringify({
                      type: 'tool-call',
                      toolCallId: toolCall.id,
                      toolName: 'generate_flowchart',
                      args: args,
                    });
                    controller.enqueue(encoder.encode(`data: ${data}\n\n`));
                  } catch (error) {
                    console.error('Error parsing flowchart args:', error);
                  }
                } else if (toolCall.function.name === 'get_canvas_state') {
                  const data = JSON.stringify({
                    type: 'tool-call',
                    toolCallId: toolCall.id,
                    toolName: 'get_canvas_state',
                    args: {},
                  });
                  controller.enqueue(encoder.encode(`data: ${data}\n\n`));
                }
              }

              // å‘é€å®Œæˆä¿¡å·
              const finishData = JSON.stringify({
                type: 'finish',
                content:
                  accumulatedContent || 'Tool calls completed successfully.',
                toolCallsCompleted: true,
              });
              controller.enqueue(encoder.encode(`data: ${finishData}\n\n`));
            } else if (chunk.choices[0]?.finish_reason === 'stop') {
              // æ™®é€šå¯¹è¯å®Œæˆ
              const finishData = JSON.stringify({
                type: 'finish',
                content: accumulatedContent || 'Conversation completed.',
              });
              controller.enqueue(encoder.encode(`data: ${finishData}\n\n`));
            }
          }

          // å‘é€ç»“æŸä¿¡å·
          controller.enqueue(encoder.encode('data: [DONE]\n\n'));
        } catch (error: any) {
          console.error('FlowChart API Error:', error);

          // Record failed usage
          if (isGuestUser) {
            await recordGuestAIUsage(req, 'flowchart_generation', false);
          } else if (userId) {
            await recordAIUsage(userId, 'flowchart_generation', {
              tokensUsed: 0,
              model: model,
              success: false,
              errorMessage: error.message,
              metadata: { messageCount: messages.length },
            });
          }

          const errorData = JSON.stringify({
            type: 'error',
            error:
              error.message ||
              'An error occurred while processing your request.',
          });
          controller.enqueue(encoder.encode(`data: ${errorData}\n\n`));
        } finally {
          controller.close();
        }
      },
    });

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        Connection: 'keep-alive',
      },
    });
  } catch (error: any) {
    console.error('FlowChart API Error:', error);

    // Record failed usage if we have userId or is guest
    if (isGuestUser) {
      try {
        await recordGuestAIUsage(req, 'flowchart_generation', false);
      } catch (recordError) {
        console.error('Failed to record guest AI usage:', recordError);
      }
    } else if (userId) {
      try {
        await recordAIUsage(userId, 'flowchart_generation', {
          tokensUsed: 0,
          model: 'google/gemini-2.5-flash',
          success: false,
          errorMessage: error.message,
          metadata: {},
        });
      } catch (recordError) {
        console.error('Failed to record AI usage:', recordError);
      }
    }

    return new Response(
      JSON.stringify({
        error: 'Internal server error',
        message: error.message || 'An unexpected error occurred.',
      }),
      {
        status: 500,
        headers: { 'Content-Type': 'application/json' },
      }
    );
  }
}
